/*
 Navicat Premium Data Transfer

 Source Server         : MySql
 Source Server Type    : MySQL
 Source Server Version : 50732
 Source Host           : 129.211.93.165:3306
 Source Schema         : imilateqq

 Target Server Type    : MySQL
 Target Server Version : 50732
 File Encoding         : 65001

 Date: 07/12/2020 17:26:47
*/

SET NAMES utf8mb4;
SET FOREIGN_KEY_CHECKS = 0;

-- ----------------------------
-- Table structure for article
-- ----------------------------
DROP TABLE IF EXISTS `article`;
CREATE TABLE `article`  (
  `title` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `md` mediumtext CHARACTER SET utf8 COLLATE utf8_general_ci NULL,
  `html` mediumtext CHARACTER SET utf8 COLLATE utf8_general_ci NULL,
  `userid` int(11) NOT NULL,
  `articletype` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `pageviews` int(11) NULL DEFAULT NULL,
  `time` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `comments` int(11) NULL DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 17 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of article
-- ----------------------------
INSERT INTO `article` VALUES ('关于使用bootstrap-fileinput上传文件进度一直为上传中的问题', 1, '因为第一次使用bootstrap-fileinput进行文件上传，找了很久都没有发现文件上传进度一直为上传中的问题，无奈之下只能去官网查看文档才发现文件上传后服务器必须返回一个json对象\r\n![](assert/uploadImages/20200722085815118.png)\r\n[官方文档](https://plugins.krajee.com/file-input#ajax-submission \"官方文档\")', '<p>因为第一次使用bootstrap-fileinput进行文件上传，找了很久都没有发现文件上传进度一直为上传中的问题，无奈之下只能去官网查看文档才发现文件上传后服务器必须返回一个json对象<br><img src=\"assert/uploadImages/20200722085815118.png\" alt=\"\"><br><a href=\"https://plugins.krajee.com/file-input#ajax-submission\" title=\"官方文档\">官方文档</a></p>\r', 1, 'bootstrap', 21, '2020-10-21 15:32:56', 1);
INSERT INTO `article` VALUES ('springboot使用通用mapper返回主键id', 2, '加上这三个注解就行了\r\n@Id\r\n@Column(name = “id”)\r\n@KeySql(useGeneratedKeys = true)\r\n```java\r\npackage com.example.pluginstest.dao;\r\n\r\nimport tk.mybatis.mapper.annotation.KeySql;\r\n\r\nimport javax.persistence.*;\r\n\r\n/**\r\n * @author zhang\r\n * @date 2020-7-21\r\n */\r\npublic class User {\r\n    @Id\r\n    @Column(name = \"id\")\r\n    @KeySql(useGeneratedKeys = true)\r\n    private int id;\r\n    private String name;\r\n    private String sex;\r\n\r\n    @Override\r\n    public String toString() {\r\n        return \"User{\" +\r\n                \"id=\" + id +\r\n                \", name=\'\" + name + \'\\\'\' +\r\n                \", sex=\'\" + sex + \'\\\'\' +\r\n                \'}\';\r\n    }\r\n\r\n    public int getId() {\r\n        return id;\r\n    }\r\n\r\n    public void setId(int id) {\r\n        this.id = id;\r\n    }\r\n\r\n    public String getName() {\r\n        return name;\r\n    }\r\n\r\n    public void setName(String name) {\r\n        this.name = name;\r\n    }\r\n\r\n    public String getSex() {\r\n        return sex;\r\n    }\r\n\r\n    public void setSex(String sex) {\r\n        this.sex = sex;\r\n    }\r\n}\r\n\r\n\r\n```\r\n', '<p>加上这三个注解就行了<br><a href=\"https://github.com/Id\" title=\"&#64;Id\" class=\"at-link\">@Id</a><br><a href=\"https://github.com/Column\" title=\"&#64;Column\" class=\"at-link\">@Column</a>(name = “id”)<br><a href=\"https://github.com/KeySql\" title=\"&#64;KeySql\" class=\"at-link\">@KeySql</a>(useGeneratedKeys = true)</p>\r\n<pre><code class=\"lang-java\">package com.example.pluginstest.dao;\r\n\r\nimport tk.mybatis.mapper.annotation.KeySql;\r\n\r\nimport javax.persistence.*;\r\n\r\n/**\r\n * @author zhang\r\n * @date 2020-7-21\r\n */\r\npublic class User {\r\n    @Id\r\n    @Column(name = &quot;id&quot;)\r\n    @KeySql(useGeneratedKeys = true)\r\n    private int id;\r\n    private String name;\r\n    private String sex;\r\n\r\n    @Override\r\n    public String toString() {\r\n        return &quot;User{&quot; +\r\n                &quot;id=&quot; + id +\r\n                &quot;, name=&#39;&quot; + name + &#39;\\&#39;&#39; +\r\n                &quot;, sex=&#39;&quot; + sex + &#39;\\&#39;&#39; +\r\n                &#39;}&#39;;\r\n    }\r\n\r\n    public int getId() {\r\n        return id;\r\n    }\r\n\r\n    public void setId(int id) {\r\n        this.id = id;\r\n    }\r\n\r\n    public String getName() {\r\n        return name;\r\n    }\r\n\r\n    public void setName(String name) {\r\n        this.name = name;\r\n    }\r\n\r\n    public String getSex() {\r\n        return sex;\r\n    }\r\n\r\n    public void setSex(String sex) {\r\n        this.sex = sex;\r\n    }\r\n}\r\n</code></pre>\r\n', 1, 'springboot', 41, '2020-10-21 15:37:26', 3);
INSERT INTO `article` VALUES ('springboot使用通用mapper返回主键id', 3, '加上这三个注解就行了\r\n@Id\r\n@Column(name = “id”)\r\n@KeySql(useGeneratedKeys = true)\r\n```java\r\npackage com.example.pluginstest.dao;\r\n\r\nimport tk.mybatis.mapper.annotation.KeySql;\r\n\r\nimport javax.persistence.*;\r\n\r\n/**\r\n * @author zhang\r\n * @date 2020-7-21\r\n */\r\npublic class User {\r\n    @Id\r\n    @Column(name = \"id\")\r\n    @KeySql(useGeneratedKeys = true)\r\n    private int id;\r\n    private String name;\r\n    private String sex;\r\n\r\n    @Override\r\n    public String toString() {\r\n        return \"User{\" +\r\n                \"id=\" + id +\r\n                \", name=\'\" + name + \'\\\'\' +\r\n                \", sex=\'\" + sex + \'\\\'\' +\r\n                \'}\';\r\n    }\r\n\r\n    public int getId() {\r\n        return id;\r\n    }\r\n\r\n    public void setId(int id) {\r\n        this.id = id;\r\n    }\r\n\r\n    public String getName() {\r\n        return name;\r\n    }\r\n\r\n    public void setName(String name) {\r\n        this.name = name;\r\n    }\r\n\r\n    public String getSex() {\r\n        return sex;\r\n    }\r\n\r\n    public void setSex(String sex) {\r\n        this.sex = sex;\r\n    }\r\n}\r\n\r\n\r\n```\r\n', '<p>加上这三个注解就行了<br><a href=\"https://github.com/Id\" title=\"&#64;Id\" class=\"at-link\">@Id</a><br><a href=\"https://github.com/Column\" title=\"&#64;Column\" class=\"at-link\">@Column</a>(name = “id”)<br><a href=\"https://github.com/KeySql\" title=\"&#64;KeySql\" class=\"at-link\">@KeySql</a>(useGeneratedKeys = true)</p>\r\n<pre><code class=\"lang-java\">package com.example.pluginstest.dao;\r\n\r\nimport tk.mybatis.mapper.annotation.KeySql;\r\n\r\nimport javax.persistence.*;\r\n\r\n/**\r\n * @author zhang\r\n * @date 2020-7-21\r\n */\r\npublic class User {\r\n    @Id\r\n    @Column(name = &quot;id&quot;)\r\n    @KeySql(useGeneratedKeys = true)\r\n    private int id;\r\n    private String name;\r\n    private String sex;\r\n\r\n    @Override\r\n    public String toString() {\r\n        return &quot;User{&quot; +\r\n                &quot;id=&quot; + id +\r\n                &quot;, name=&#39;&quot; + name + &#39;\\&#39;&#39; +\r\n                &quot;, sex=&#39;&quot; + sex + &#39;\\&#39;&#39; +\r\n                &#39;}&#39;;\r\n    }\r\n\r\n    public int getId() {\r\n        return id;\r\n    }\r\n\r\n    public void setId(int id) {\r\n        this.id = id;\r\n    }\r\n\r\n    public String getName() {\r\n        return name;\r\n    }\r\n\r\n    public void setName(String name) {\r\n        this.name = name;\r\n    }\r\n\r\n    public String getSex() {\r\n        return sex;\r\n    }\r\n\r\n    public void setSex(String sex) {\r\n        this.sex = sex;\r\n    }\r\n}\r\n</code></pre>\r\n', 1, 'springboot', 5, '2020-10-21 15:38:45', 0);
INSERT INTO `article` VALUES ('easyexcel填充复杂表格并导出以及使用easyexcel遇到的坑', 4, '读取模板时出现Your file appears not to be a valid OLE2 document\r\n解决办法：另存为97-03年的xls格式即可\r\n\r\n![](assert/uploadImages/20200717103540168.png)\r\n\r\n准备一个填充模板![](assert/uploadImages/20200717103850500.png)\r\n\r\n其中{xxx}为普通变量，{.xxx} 的为list变量\r\n\r\n准备一个实体类\r\n\r\n```java\r\npublic class vo {\r\n    private String terminal;\r\n    private String color;\r\n    private String number;\r\n    private String zq;\r\n    private String dx;\r\n    private String zt;\r\n    private String zd;\r\n    private String rk;\r\n\r\n    public String getTerminal() {\r\n        return terminal;\r\n    }\r\n\r\n    public void setTerminal(String terminal) {\r\n        this.terminal = terminal;\r\n    }\r\n\r\n    public String getColor() {\r\n        return color;\r\n    }\r\n\r\n    public void setColor(String color) {\r\n        this.color = color;\r\n    }\r\n\r\n    public String getNumber() {\r\n        return number;\r\n    }\r\n\r\n    public void setNumber(String number) {\r\n        this.number = number;\r\n    }\r\n\r\n    public String getZq() {\r\n        return zq;\r\n    }\r\n\r\n    public void setZq(String zq) {\r\n        this.zq = zq;\r\n    }\r\n\r\n    public String getDx() {\r\n        return dx;\r\n    }\r\n\r\n    public void setDx(String dx) {\r\n        this.dx = dx;\r\n    }\r\n\r\n    public String getZt() {\r\n        return zt;\r\n    }\r\n\r\n    public void setZt(String zt) {\r\n        this.zt = zt;\r\n    }\r\n\r\n    public String getZd() {\r\n        return zd;\r\n    }\r\n\r\n    public void setZd(String zd) {\r\n        this.zd = zd;\r\n    }\r\n\r\n    public String getRk() {\r\n        return rk;\r\n    }\r\n\r\n    public void setRk(String rk) {\r\n        this.rk = rk;\r\n    }\r\n}\r\n\r\n```\r\n一个处理导出的controller类\r\n```java\r\n@RequestMapping(\"/expor\")\r\n    public String exporExcel(HttpServletResponse response) throws IOException {\r\n        OutputStream outputStream = response.getOutputStream();\r\n        response.setHeader(\"Content-disposition\", \"attachment; filename=\" + \"catagory.xls\");\r\n        response.setContentType(\"application/msexcel;charset=UTF-8\");//设置类型\r\n        response.setHeader(\"Pragma\", \"No-cache\");//设置头\r\n        response.setHeader(\"Cache-Control\", \"no-cache\");//设置头\r\n        response.setDateHeader(\"Expires\", 0);//设置日期头\r\n        ExcelWriter excelWriter = EasyExcel.write(outputStream).withTemplate(ResourceUtils.getFile(\"classpath:excelTemplates/template.xls\")).build();\r\n        WriteSheet writeSheet = EasyExcel.writerSheet().build();\r\n        List<vo> list =new ArrayList<vo>();\r\n        vo v = new vo();\r\n        v.setColor(\"1\");\r\n        v.setDx(\"1\");\r\n        v.setNumber(\"1\");\r\n        v.setRk(\"1\");\r\n        v.setTerminal(\"1\");\r\n        v.setZq(\"1\");\r\n        v.setZt(\"1\");\r\n        v.setRk(\"1\");\r\n        list.add(v);\r\n        FillConfig fillConfig = FillConfig.builder().forceNewRow(Boolean.TRUE).build();\r\n        //填充两行list\r\n        excelWriter.fill(list, fillConfig, writeSheet);\r\n        excelWriter.fill(list, fillConfig, writeSheet);\r\n        //填充普通变量\r\n        Map<String, Object> map = new HashMap<String, Object>();\r\n        map.put(\"bussinessRequest\", \"1\");\r\n        map.put(\"linkman\", \"1\");\r\n        map.put(\"linkphone\", \"1\");\r\n        map.put(\"orderdate\", \"1\");\r\n        map.put(\"leaddate\", \"1\");\r\n        map.put(\"entrct\", \"1\");\r\n        map.put(\"comstomer\", \"1\");\r\n        excelWriter.fill(map, writeSheet);\r\n        excelWriter.finish();\r\n        outputStream.flush();\r\n        response.getOutputStream().close();\r\n        return \"system/test/tableTest\";\r\n    }\r\n\r\n```\r\n\r\n填充后并导出的效果，因为controller中忘记设置zd的值所以图中对应zd的表格并没有值\r\n![](assert/uploadImages/20200717105259517.png)\r\n更多easyexcel用法可以查看https://www.yuque.com/easyexcel/doc/fill', '<p>读取模板时出现Your file appears not to be a valid OLE2 document<br>解决办法：另存为97-03年的xls格式即可</p>\r\n<p><img src=\"assert/uploadImages/20200717103540168.png\" alt=\"\"></p>\r\n<p>准备一个填充模板<img src=\"assert/uploadImages/20200717103850500.png\" alt=\"\"></p>\r\n<p>其中{xxx}为普通变量，{.xxx} 的为list变量</p>\r\n<p>准备一个实体类</p>\r\n<pre><code class=\"lang-java\">public class vo {\r\n    private String terminal;\r\n    private String color;\r\n    private String number;\r\n    private String zq;\r\n    private String dx;\r\n    private String zt;\r\n    private String zd;\r\n    private String rk;\r\n\r\n    public String getTerminal() {\r\n        return terminal;\r\n    }\r\n\r\n    public void setTerminal(String terminal) {\r\n        this.terminal = terminal;\r\n    }\r\n\r\n    public String getColor() {\r\n        return color;\r\n    }\r\n\r\n    public void setColor(String color) {\r\n        this.color = color;\r\n    }\r\n\r\n    public String getNumber() {\r\n        return number;\r\n    }\r\n\r\n    public void setNumber(String number) {\r\n        this.number = number;\r\n    }\r\n\r\n    public String getZq() {\r\n        return zq;\r\n    }\r\n\r\n    public void setZq(String zq) {\r\n        this.zq = zq;\r\n    }\r\n\r\n    public String getDx() {\r\n        return dx;\r\n    }\r\n\r\n    public void setDx(String dx) {\r\n        this.dx = dx;\r\n    }\r\n\r\n    public String getZt() {\r\n        return zt;\r\n    }\r\n\r\n    public void setZt(String zt) {\r\n        this.zt = zt;\r\n    }\r\n\r\n    public String getZd() {\r\n        return zd;\r\n    }\r\n\r\n    public void setZd(String zd) {\r\n        this.zd = zd;\r\n    }\r\n\r\n    public String getRk() {\r\n        return rk;\r\n    }\r\n\r\n    public void setRk(String rk) {\r\n        this.rk = rk;\r\n    }\r\n}\r\n</code></pre>\r\n<p>一个处理导出的controller类</p>\r\n<pre><code class=\"lang-java\">@RequestMapping(&quot;/expor&quot;)\r\n    public String exporExcel(HttpServletResponse response) throws IOException {\r\n        OutputStream outputStream = response.getOutputStream();\r\n        response.setHeader(&quot;Content-disposition&quot;, &quot;attachment; filename=&quot; + &quot;catagory.xls&quot;);\r\n        response.setContentType(&quot;application/msexcel;charset=UTF-8&quot;);//设置类型\r\n        response.setHeader(&quot;Pragma&quot;, &quot;No-cache&quot;);//设置头\r\n        response.setHeader(&quot;Cache-Control&quot;, &quot;no-cache&quot;);//设置头\r\n        response.setDateHeader(&quot;Expires&quot;, 0);//设置日期头\r\n        ExcelWriter excelWriter = EasyExcel.write(outputStream).withTemplate(ResourceUtils.getFile(&quot;classpath:excelTemplates/template.xls&quot;)).build();\r\n        WriteSheet writeSheet = EasyExcel.writerSheet().build();\r\n        List&lt;vo&gt; list =new ArrayList&lt;vo&gt;();\r\n        vo v = new vo();\r\n        v.setColor(&quot;1&quot;);\r\n        v.setDx(&quot;1&quot;);\r\n        v.setNumber(&quot;1&quot;);\r\n        v.setRk(&quot;1&quot;);\r\n        v.setTerminal(&quot;1&quot;);\r\n        v.setZq(&quot;1&quot;);\r\n        v.setZt(&quot;1&quot;);\r\n        v.setRk(&quot;1&quot;);\r\n        list.add(v);\r\n        FillConfig fillConfig = FillConfig.builder().forceNewRow(Boolean.TRUE).build();\r\n        //填充两行list\r\n        excelWriter.fill(list, fillConfig, writeSheet);\r\n        excelWriter.fill(list, fillConfig, writeSheet);\r\n        //填充普通变量\r\n        Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;();\r\n        map.put(&quot;bussinessRequest&quot;, &quot;1&quot;);\r\n        map.put(&quot;linkman&quot;, &quot;1&quot;);\r\n        map.put(&quot;linkphone&quot;, &quot;1&quot;);\r\n        map.put(&quot;orderdate&quot;, &quot;1&quot;);\r\n        map.put(&quot;leaddate&quot;, &quot;1&quot;);\r\n        map.put(&quot;entrct&quot;, &quot;1&quot;);\r\n        map.put(&quot;comstomer&quot;, &quot;1&quot;);\r\n        excelWriter.fill(map, writeSheet);\r\n        excelWriter.finish();\r\n        outputStream.flush();\r\n        response.getOutputStream().close();\r\n        return &quot;system/test/tableTest&quot;;\r\n    }\r\n</code></pre>\r\n<p>填充后并导出的效果，因为controller中忘记设置zd的值所以图中对应zd的表格并没有值<br><img src=\"assert/uploadImages/20200717105259517.png\" alt=\"\"><br>更多easyexcel用法可以查看<a href=\"https://www.yuque.com/easyexcel/doc/fill\">https://www.yuque.com/easyexcel/doc/fill</a></p>\r\n', 1, 'easyexcel', 17, '2020-10-21 15:51:40', 3);
INSERT INTO `article` VALUES ('Ubuntu 18.04安装elasticsearch修改limits.conf不生效的问题', 5, '如果你想增加 ulimit -n 显示的极限值，你可以：\r\n\r\n修改 /etc/systemd/user.conf 及 /etc/systemd/system.conf 中如下面这行的配置项（这将处理图形登录）：\r\nDefaultLimitNOFILE=655360\r\n\r\n修改 /etc/security/limits.conf 中如下面这几行（这将处理非图形登录）：\r\n* soft nofile 655360\r\n* hard nofile 655360\r\n\r\n最后特别提醒大家一句，这三个地方的文件改好之后，一定要重启系统才得以生效哟！！', '<p>如果你想增加 ulimit -n 显示的极限值，你可以：</p>\r\n<p>修改 /etc/systemd/user.conf 及 /etc/systemd/system.conf 中如下面这行的配置项（这将处理图形登录）：<br>DefaultLimitNOFILE=655360</p>\r\n<p>修改 /etc/security/limits.conf 中如下面这几行（这将处理非图形登录）：</p>\r\n<ul>\r\n<li>soft nofile 655360</li><li>hard nofile 655360</li></ul>\r\n<p>最后特别提醒大家一句，这三个地方的文件改好之后，一定要重启系统才得以生效哟！！</p>\r\n', 1, 'Ubuntu', 32, '2020-10-22 17:48:38', 0);
INSERT INTO `article` VALUES ('编译thrift出现找不到libboost_unit_test_framework.a错误', 6, '解决方法：安装libboost-all-dev依赖即可', '<p>解决方法：安装libboost-all-dev依赖即可</p>\r\n', 1, 'thrift', 17, '2020-10-23 11:33:38', 0);
INSERT INTO `article` VALUES ('springboot1.5整合redisson出现java.io.IOException: 远程主机强迫关闭了一个现有的连接.', 7, '编写了一个测试类看是否整合成功\r\n![](https://img-blog.csdnimg.cn/20200304114841920.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dmemRnZA==,size_16,color_FFFFFF,t_70)\r\n\r\n可以打个断点debug测试让链接不会因为程序结束而断开\r\n![](https://img-blog.csdnimg.cn/2020030411521834.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dmemRnZA==,size_16,color_FFFFFF,t_70)\r\n\r\n具体原因可以参考\r\n![](https://img-blog.csdnimg.cn/20200304114957571.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dmemRnZA==,size_16,color_FFFFFF,t_70)', '<p>编写了一个测试类看是否整合成功<br><img src=\"https://img-blog.csdnimg.cn/20200304114841920.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dmemRnZA==,size_16,color_FFFFFF,t_70\" alt=\"\"></p>\r\n<p>可以打个断点debug测试让链接不会因为程序结束而断开<br><img src=\"https://img-blog.csdnimg.cn/2020030411521834.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dmemRnZA==,size_16,color_FFFFFF,t_70\" alt=\"\"></p>\r\n<p>具体原因可以参考<br><img src=\"https://img-blog.csdnimg.cn/20200304114957571.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dmemRnZA==,size_16,color_FFFFFF,t_70\" alt=\"\"></p>\r\n', 1, 'springboot', 51, '2020-10-23 11:58:13', 0);
INSERT INTO `article` VALUES ('环境：spark2.2.0，kafka0.10.0，scala2.11.0', 8, '环境：spark2.2.0，kafka0.10.0，scala2.11.0\r\n```scala\r\ndef main(args: Array[String]): Unit = {\r\n    System.setProperty(\"hadoop.home.dir\", \"D:\\\\Program Files\\\\hadoop\\\\hadoop-2.7.7\")\r\n    val spark = SparkSession.builder()\r\n      .appName(\"socketStreaming\")\r\n      .master(\"spark://bigdata.slave01.com:7077\")\r\n      .getOrCreate()\r\n    val url = \"jdbc:mysql://bigdata.master.com:3306/mytrain\"\r\n    val username = \"root\"\r\n    val password = \"123456\"\r\n    val writer = new JDBCSink(url, username, password)\r\n    import spark.implicits._\r\n    val lines = spark.readStream\r\n      .format(\"kafka\")\r\n      .option(\"kafka.bootstrap.servers\", \"bigdata.master.com:9092,bigdata.slave01.com:9092,bigdata.slave02.com:9092\")\r\n      .option(\"subscribe\", \"train\")\r\n      .load()\r\n      .selectExpr(\"CAST(value AS STRING)\").as[String]\r\n    val words = lines.map(_.split(\",\")).map(x => {\r\n        (x(0), x(1), x(2), x(3)\r\n          , x(4), x(5), x(6), x(7)\r\n          , x(8), x(9), x(10), x(11)\r\n          , x(12), -1*(x(13).toInt), x(14).toInt,\r\n          x(15), x(16))\r\n    })\r\n      .toDF(\"shdm\", \"shmc\",\r\n        \"xflb\", \"jydd\",\r\n        \"jylx\", \"digitalsign\",\r\n        \"sfrzh\", \"xm\",\r\n        \"kh\", \"jyrq\",\r\n        \"jysj\", \"jylsh\",\r\n        \"zdjh\", \"jyje\",\r\n        \"kye\", \"xtdm\",\r\n        \"xtmc\")\r\n    val wordCounts = words.filter(words(\"jyje\") > 0).groupBy(\"shmc\").agg((\"jyje\", \"sum\")).withColumnRenamed(\"sum(jyje)\", \"jyje\")\r\n    wordCounts.printSchema()\r\n    val query = wordCounts.writeStream.foreach(writer).outputMode(\"update\")\r\n      .start()\r\n\r\n\r\n\r\n    var count=0\r\n    while(true){\r\n      if(query.lastProgress!=null){\r\n        if(query.lastProgress.processedRowsPerSecond==0&&query.lastProgress.stateOperators(0).numRowsTotal!=0){\r\n          count=count+1\r\n          if(count==2) {//设置连续两次没有数据更新自动停止任务\r\n            spark.stop()\r\n            System.exit(0)\r\n          }\r\n        }else{\r\n            count=0\r\n         }\r\n      }\r\n\r\n    }\r\n  }\r\n\r\n```\r\nquery.lastProgress的内容为\r\n```json\r\n{\r\n\"id\" : \"ce011fdc-8762-4dcb-84eb-a77333e28109\",\r\n\"runId\" : \"88e2ff94-ede0-45a8-b687-6316fbef529a\",\r\n\"name\" : \"MyQuery\",\r\n\"timestamp\" : \"2016-12-14T18:45:24.873Z\",\r\n\"numInputRows\" : 10,\r\n\"inputRowsPerSecond\" : 120.0,\r\n\"processedRowsPerSecond\" : 200.0,//按个人理解，当数据更新完毕后，即全部数据更新至mysql，此数据会变为0，且未开始消费数据时此数据也为0\r\n\"durationMs\" : {\r\n  \"triggerExecution\" : 3,\r\n  \"getOffset\" : 2\r\n},\r\n\"eventTime\" : {\r\n  \"watermark\" : \"2016-12-14T18:45:24.873Z\"\r\n},\r\n\"stateOperators\" : [{\r\n  \"numRowsTotal\":0,//按个人理解，当数据更新时，此为更新的总记录数\r\n   ........\r\n}],\r\n\"sources\" : [ {\r\n  \"description\" : \"KafkaSource[Subscribe[topic-0]]\",\r\n  \"startOffset\" : {\r\n    \"topic-0\" : {\r\n      \"2\" : 0,\r\n      \"4\" : 1,\r\n      \"1\" : 1,\r\n      \"3\" : 1,\r\n      \"0\" : 1\r\n    }\r\n  },\r\n  \"endOffset\" : {\r\n    \"topic-0\" : {\r\n      \"2\" : 0,\r\n      \"4\" : 115,\r\n      \"1\" : 134,\r\n      \"3\" : 21,\r\n      \"0\" : 534\r\n    }\r\n  },\r\n  \"numInputRows\" : 10,\r\n  \"inputRowsPerSecond\" : 120.0,\r\n  \"processedRowsPerSecond\" : 200.0\r\n} ],\r\n\"sink\" : {\r\n  \"description\" : \"MemorySink\"\r\n}\r\n}\r\n\r\n\r\n\r\n```\r\n', '<p>环境：spark2.2.0，kafka0.10.0，scala2.11.0</p>\r\n<pre><code class=\"lang-scala\">def main(args: Array[String]): Unit = {\r\n    System.setProperty(&quot;hadoop.home.dir&quot;, &quot;D:\\\\Program Files\\\\hadoop\\\\hadoop-2.7.7&quot;)\r\n    val spark = SparkSession.builder()\r\n      .appName(&quot;socketStreaming&quot;)\r\n      .master(&quot;spark://bigdata.slave01.com:7077&quot;)\r\n      .getOrCreate()\r\n    val url = &quot;jdbc:mysql://bigdata.master.com:3306/mytrain&quot;\r\n    val username = &quot;root&quot;\r\n    val password = &quot;123456&quot;\r\n    val writer = new JDBCSink(url, username, password)\r\n    import spark.implicits._\r\n    val lines = spark.readStream\r\n      .format(&quot;kafka&quot;)\r\n      .option(&quot;kafka.bootstrap.servers&quot;, &quot;bigdata.master.com:9092,bigdata.slave01.com:9092,bigdata.slave02.com:9092&quot;)\r\n      .option(&quot;subscribe&quot;, &quot;train&quot;)\r\n      .load()\r\n      .selectExpr(&quot;CAST(value AS STRING)&quot;).as[String]\r\n    val words = lines.map(_.split(&quot;,&quot;)).map(x =&gt; {\r\n        (x(0), x(1), x(2), x(3)\r\n          , x(4), x(5), x(6), x(7)\r\n          , x(8), x(9), x(10), x(11)\r\n          , x(12), -1*(x(13).toInt), x(14).toInt,\r\n          x(15), x(16))\r\n    })\r\n      .toDF(&quot;shdm&quot;, &quot;shmc&quot;,\r\n        &quot;xflb&quot;, &quot;jydd&quot;,\r\n        &quot;jylx&quot;, &quot;digitalsign&quot;,\r\n        &quot;sfrzh&quot;, &quot;xm&quot;,\r\n        &quot;kh&quot;, &quot;jyrq&quot;,\r\n        &quot;jysj&quot;, &quot;jylsh&quot;,\r\n        &quot;zdjh&quot;, &quot;jyje&quot;,\r\n        &quot;kye&quot;, &quot;xtdm&quot;,\r\n        &quot;xtmc&quot;)\r\n    val wordCounts = words.filter(words(&quot;jyje&quot;) &gt; 0).groupBy(&quot;shmc&quot;).agg((&quot;jyje&quot;, &quot;sum&quot;)).withColumnRenamed(&quot;sum(jyje)&quot;, &quot;jyje&quot;)\r\n    wordCounts.printSchema()\r\n    val query = wordCounts.writeStream.foreach(writer).outputMode(&quot;update&quot;)\r\n      .start()\r\n\r\n\r\n\r\n    var count=0\r\n    while(true){\r\n      if(query.lastProgress!=null){\r\n        if(query.lastProgress.processedRowsPerSecond==0&amp;&amp;query.lastProgress.stateOperators(0).numRowsTotal!=0){\r\n          count=count+1\r\n          if(count==2) {//设置连续两次没有数据更新自动停止任务\r\n            spark.stop()\r\n            System.exit(0)\r\n          }\r\n        }else{\r\n            count=0\r\n         }\r\n      }\r\n\r\n    }\r\n  }\r\n</code></pre>\r\n<p>query.lastProgress的内容为</p>\r\n<pre><code class=\"lang-json\">{\r\n&quot;id&quot; : &quot;ce011fdc-8762-4dcb-84eb-a77333e28109&quot;,\r\n&quot;runId&quot; : &quot;88e2ff94-ede0-45a8-b687-6316fbef529a&quot;,\r\n&quot;name&quot; : &quot;MyQuery&quot;,\r\n&quot;timestamp&quot; : &quot;2016-12-14T18:45:24.873Z&quot;,\r\n&quot;numInputRows&quot; : 10,\r\n&quot;inputRowsPerSecond&quot; : 120.0,\r\n&quot;processedRowsPerSecond&quot; : 200.0,//按个人理解，当数据更新完毕后，即全部数据更新至mysql，此数据会变为0，且未开始消费数据时此数据也为0\r\n&quot;durationMs&quot; : {\r\n  &quot;triggerExecution&quot; : 3,\r\n  &quot;getOffset&quot; : 2\r\n},\r\n&quot;eventTime&quot; : {\r\n  &quot;watermark&quot; : &quot;2016-12-14T18:45:24.873Z&quot;\r\n},\r\n&quot;stateOperators&quot; : [{\r\n  &quot;numRowsTotal&quot;:0,//按个人理解，当数据更新时，此为更新的总记录数\r\n   ........\r\n}],\r\n&quot;sources&quot; : [ {\r\n  &quot;description&quot; : &quot;KafkaSource[Subscribe[topic-0]]&quot;,\r\n  &quot;startOffset&quot; : {\r\n    &quot;topic-0&quot; : {\r\n      &quot;2&quot; : 0,\r\n      &quot;4&quot; : 1,\r\n      &quot;1&quot; : 1,\r\n      &quot;3&quot; : 1,\r\n      &quot;0&quot; : 1\r\n    }\r\n  },\r\n  &quot;endOffset&quot; : {\r\n    &quot;topic-0&quot; : {\r\n      &quot;2&quot; : 0,\r\n      &quot;4&quot; : 115,\r\n      &quot;1&quot; : 134,\r\n      &quot;3&quot; : 21,\r\n      &quot;0&quot; : 534\r\n    }\r\n  },\r\n  &quot;numInputRows&quot; : 10,\r\n  &quot;inputRowsPerSecond&quot; : 120.0,\r\n  &quot;processedRowsPerSecond&quot; : 200.0\r\n} ],\r\n&quot;sink&quot; : {\r\n  &quot;description&quot; : &quot;MemorySink&quot;\r\n}\r\n}\r\n</code></pre>\r\n', 1, 'spark', 9, '2020-10-23 12:00:42', 1);
INSERT INTO `article` VALUES ('spark2.2.0编译及遇到的问题', 9, '环境\r\n1）java8\r\n2）hadoop2.7.3\r\n3）scala2.11.2\r\n4）R3.4.4（如果不需要sparkR的话R可以不用）\r\n修改spark目录下的dev/make-distribution.sh脚本文件\r\n\r\n![](https://img-blog.csdnimg.cn/20190723124933807.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dmemRnZA==,size_16,color_FFFFFF,t_70)\r\n\r\n把对应代码的改成自己对应的版本（可以加快编译速度不用脚本自行寻找版本）\r\n编译之前需要安装一些依赖：\r\nsudo apt install pandoc\r\npip install pypandoc\r\n如果需要sparkR支持还需要在R命令行安装一些包：\r\ninstall.packages(“knitr”)\r\ninstall.packages(“rmarkdown”)\r\ninstall.packages(“e1071”)\r\ninstall.packages(“testthat”)\r\n编译sparkR所需的依赖：\r\nsudo apt install texlive-latex-base\r\nsudo apt install texlive-latex-recommended\r\nsudo apt install texlive-latex-extra\r\nsudo apt install texlive-fonts-recommended\r\nsudo apt install texlive-fonts-extra\r\n然后就可以进行编译了，命令为\r\n./dev/make-distribution.sh --name custom-spark --pip --r --tgz -Psparkr -Phadoop-2.7 -Phive -Phive-thriftserver -Pmesos -Pyarn\r\n参数介绍：\r\n-Phadoop：Hadoop版本号；\r\n-Pyarn ：是否支持Hadoop YARN；\r\n-Phive：是否在Spark SQL 中支持hive；\r\n-Phive-thriftserver：同-Phive；\r\n-Psparkr：是否支持sparkr；\r\n\r\n编译出现的问题\r\n1找不到sun.misc.Cleaner类\r\n![](https://img-blog.csdnimg.cn/20190723132433698.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dmemRnZA==,size_16,color_FFFFFF,t_70)\r\n原因java的版本不对\r\n解决方法：\r\n查看Linux JDK菜单\r\nupdate-alternatives --config java\r\nupdate-alternatives --config javac\r\n![](https://img-blog.csdnimg.cn/20190723132928598.png)\r\n发现我的javac选择的是java11的，把它改成8的就行了\r\n\r\n2处理标头‘sparkr-vignettes.Rmd’失败。。。。\r\n![](https://img-blog.csdnimg.cn/20190723133640513.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dmemRnZA==,size_16,color_FFFFFF,t_70)\r\n找到spark目录下R/pkg/vignettes的sparkr-vignettes.Rmd的425-426行往前面看发现可能缺少e1071的包\r\n![](https://img-blog.csdnimg.cn/20190723133954403.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dmemRnZA==,size_16,color_FFFFFF,t_70)\r\n解决方法：\r\n进入R命令行安装e1071的包\r\ninstall.packages(“e1071”)\r\n\r\n3 package suggested but not available:‘testthat’\r\n在这里插入图片描述\r\n\r\n解决方法：\r\n进入R命令行安装e1071的包\r\ninstall.packages(“testthat”)\r\n\r\n4 pdflatex is not available\r\n![](https://img-blog.csdnimg.cn/2019072313491266.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dmemRnZA==,size_16,color_FFFFFF,t_70)\r\n解决方法：\r\nsudo apt install texlive-latex-base\r\nsudo apt install texlive-latex-recommended\r\nsudo apt install texlive-latex-extra\r\nsudo apt install texlive-fonts-recommended\r\nsudo apt install texlive-fonts-extra', '<p>环境<br>1）java8<br>2）hadoop2.7.3<br>3）scala2.11.2<br>4）R3.4.4（如果不需要sparkR的话R可以不用）<br>修改spark目录下的dev/make-distribution.sh脚本文件</p>\r\n<p><img src=\"https://img-blog.csdnimg.cn/20190723124933807.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dmemRnZA==,size_16,color_FFFFFF,t_70\" alt=\"\"></p>\r\n<p>把对应代码的改成自己对应的版本（可以加快编译速度不用脚本自行寻找版本）<br>编译之前需要安装一些依赖：<br>sudo apt install pandoc<br>pip install pypandoc<br>如果需要sparkR支持还需要在R命令行安装一些包：<br>install.packages(“knitr”)<br>install.packages(“rmarkdown”)<br>install.packages(“e1071”)<br>install.packages(“testthat”)<br>编译sparkR所需的依赖：<br>sudo apt install texlive-latex-base<br>sudo apt install texlive-latex-recommended<br>sudo apt install texlive-latex-extra<br>sudo apt install texlive-fonts-recommended<br>sudo apt install texlive-fonts-extra<br>然后就可以进行编译了，命令为<br>./dev/make-distribution.sh —name custom-spark —pip —r —tgz -Psparkr -Phadoop-2.7 -Phive -Phive-thriftserver -Pmesos -Pyarn<br>参数介绍：<br>-Phadoop：Hadoop版本号；<br>-Pyarn ：是否支持Hadoop YARN；<br>-Phive：是否在Spark SQL 中支持hive；<br>-Phive-thriftserver：同-Phive；<br>-Psparkr：是否支持sparkr；</p>\r\n<p>编译出现的问题<br>1找不到sun.misc.Cleaner类<br><img src=\"https://img-blog.csdnimg.cn/20190723132433698.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dmemRnZA==,size_16,color_FFFFFF,t_70\" alt=\"\"><br>原因java的版本不对<br>解决方法：<br>查看Linux JDK菜单<br>update-alternatives —config java<br>update-alternatives —config javac<br><img src=\"https://img-blog.csdnimg.cn/20190723132928598.png\" alt=\"\"><br>发现我的javac选择的是java11的，把它改成8的就行了</p>\r\n<p>2处理标头‘sparkr-vignettes.Rmd’失败。。。。<br><img src=\"https://img-blog.csdnimg.cn/20190723133640513.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dmemRnZA==,size_16,color_FFFFFF,t_70\" alt=\"\"><br>找到spark目录下R/pkg/vignettes的sparkr-vignettes.Rmd的425-426行往前面看发现可能缺少e1071的包<br><img src=\"https://img-blog.csdnimg.cn/20190723133954403.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dmemRnZA==,size_16,color_FFFFFF,t_70\" alt=\"\"><br>解决方法：<br>进入R命令行安装e1071的包<br>install.packages(“e1071”)</p>\r\n<p>3 package suggested but not available:‘testthat’<br>在这里插入图片描述</p>\r\n<p>解决方法：<br>进入R命令行安装e1071的包<br>install.packages(“testthat”)</p>\r\n<p>4 pdflatex is not available<br><img src=\"https://img-blog.csdnimg.cn/2019072313491266.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dmemRnZA==,size_16,color_FFFFFF,t_70\" alt=\"\"><br>解决方法：<br>sudo apt install texlive-latex-base<br>sudo apt install texlive-latex-recommended<br>sudo apt install texlive-latex-extra<br>sudo apt install texlive-fonts-recommended<br>sudo apt install texlive-fonts-extra</p>\r\n', 1, 'spark', 23, '2020-10-23 12:07:41', 2);
INSERT INTO `article` VALUES ('关于gin重定向导致不能跳转到正确的路径', 10, 'StatusMovedPermanently为301永久重定向，做权限验证的时候永久重定向导致权限通过后依然不能跳转到正确路径\r\n```go\r\nr.GET(\"/test\", func(c *gin.Context) {\r\n	c.Redirect(http.StatusMovedPermanently, \"http://www.google.com/\")\r\n})\r\n\r\n```\r\n改用临时重定向就行了\r\n```go\r\nr.GET(\"/test\", func(c *gin.Context) {\r\n	c.Redirect(http.StatusTemporaryRedirect, \"http://www.google.com/\")\r\n})\r\n\r\n```', '<p>StatusMovedPermanently为301永久重定向，做权限验证的时候永久重定向导致权限通过后依然不能跳转到正确路径</p>\r\n<pre><code class=\"lang-go\">r.GET(&quot;/test&quot;, func(c *gin.Context) {\r\n    c.Redirect(http.StatusMovedPermanently, &quot;http://www.google.com/&quot;)\r\n})\r\n</code></pre>\r\n<p>改用临时重定向就行了</p>\r\n<pre><code class=\"lang-go\">r.GET(&quot;/test&quot;, func(c *gin.Context) {\r\n    c.Redirect(http.StatusTemporaryRedirect, &quot;http://www.google.com/&quot;)\r\n})\r\n</code></pre>\r\n', 1, 'go', 0, '2020-11-03 09:56:54', 0);
INSERT INTO `article` VALUES ('c++ undefined reference to `Line::Line(Line const&)‘', 16, 'c++类里面带有指针变量\r\n![](https://img-blog.csdnimg.cn/20201102145529472.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dmemRnZA==,size_16,color_FFFFFF,t_70#pic_center)\r\n如果没有实现拷贝构造函数\r\n![](https://img-blog.csdnimg.cn/20201102145731480.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dmemRnZA==,size_16,color_FFFFFF,t_70#pic_center)\r\n像这样line2=line1要调用拷贝构造函数，没有拷贝构造函数就报错了\r\n![](https://img-blog.csdnimg.cn/20201102145910189.png#pic_center)\r\n![](https://img-blog.csdnimg.cn/20201102150417828.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dmemRnZA==,size_16,color_FFFFFF,t_70#pic_center)', '<p>c++类里面带有指针变量<br><img src=\"https://img-blog.csdnimg.cn/20201102145529472.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dmemRnZA==,size_16,color_FFFFFF,t_70#pic_center\" alt=\"\"><br>如果没有实现拷贝构造函数<br><img src=\"https://img-blog.csdnimg.cn/20201102145731480.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dmemRnZA==,size_16,color_FFFFFF,t_70#pic_center\" alt=\"\"><br>像这样line2=line1要调用拷贝构造函数，没有拷贝构造函数就报错了<br><img src=\"https://img-blog.csdnimg.cn/20201102145910189.png#pic_center\" alt=\"\"><br><img src=\"https://img-blog.csdnimg.cn/20201102150417828.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dmemRnZA==,size_16,color_FFFFFF,t_70#pic_center\" alt=\"\"></p>\r\n', 2, 'c++', 2, '2020-11-03 10:21:55', 0);

-- ----------------------------
-- Table structure for comment
-- ----------------------------
DROP TABLE IF EXISTS `comment`;
CREATE TABLE `comment`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `articleid` int(11) NOT NULL,
  `comment` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `time` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `userid` int(11) NOT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 12 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of comment
-- ----------------------------
INSERT INTO `comment` VALUES (2, 8, '666', '2020-10-27 12:42:01', 1);
INSERT INTO `comment` VALUES (3, 9, '666', '2020-10-27 12:42:10', 2);
INSERT INTO `comment` VALUES (4, 2, '牛逼', '2020-10-27 12:43:06', 1);
INSERT INTO `comment` VALUES (5, 9, '楼主牛逼', '2020-10-27 12:44:06', 2);
INSERT INTO `comment` VALUES (6, 4, '666', '2020-10-27 16:49:09', 1);
INSERT INTO `comment` VALUES (7, 2, 'dddd', '2020-10-27 17:38:55', 2);
INSERT INTO `comment` VALUES (8, 1, '666', '2020-11-16 13:41:00', 1);
INSERT INTO `comment` VALUES (9, 2, '666', '2020-11-17 17:34:41', 2);
INSERT INTO `comment` VALUES (10, 4, '666', '2020-11-18 09:27:02', 1);
INSERT INTO `comment` VALUES (11, 4, '哈哈哈', '2020-11-18 09:27:46', 1);

-- ----------------------------
-- Table structure for source
-- ----------------------------
DROP TABLE IF EXISTS `source`;
CREATE TABLE `source`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `sourcepath` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `userid` int(11) NOT NULL,
  `sourcetype` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `sourcecomment` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `sourcename` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of source
-- ----------------------------

-- ----------------------------
-- Table structure for user
-- ----------------------------
DROP TABLE IF EXISTS `user`;
CREATE TABLE `user`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `username` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `password` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `email` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `state` int(255) NULL DEFAULT NULL,
  `nickname` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `gender` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `province` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `country` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `phonenumber` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 3 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of user
-- ----------------------------
INSERT INTO `user` VALUES (1, 'adsf', '872be7378d2e5c4b747f2547144c6dc5', '', 0, '', '', '', '', '15815933612');
INSERT INTO `user` VALUES (2, 'forward', '872be7378d2e5c4b747f2547144c6dc5', '', 0, '', '', '', '', '13727634257');

-- ----------------------------
-- Table structure for userinfo
-- ----------------------------
DROP TABLE IF EXISTS `userinfo`;
CREATE TABLE `userinfo`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `userid` int(11) NOT NULL,
  `nickname` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `selfintroduction` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `avatar` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `address` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  PRIMARY KEY (`id`, `userid`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 5 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of userinfo
-- ----------------------------
INSERT INTO `userinfo` VALUES (3, 1, 'oldfriend', '一个c++程序员', 'assert/uploadAvatars/Koala.jpg', '  深圳');
INSERT INTO `userinfo` VALUES (4, 2, 'forward', '一个java程序员', 'assert/uploadAvatars/Jellyfish.jpg', '  深圳');

SET FOREIGN_KEY_CHECKS = 1;
